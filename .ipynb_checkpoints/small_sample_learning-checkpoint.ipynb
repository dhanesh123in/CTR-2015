{
 "metadata": {
  "name": "",
  "signature": "sha256:ef30382eeeebdfca5df9c9a7bc719efb69d3f23b39a822498efe991450166818"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import BernoulliNB as bnb\n",
      "from sklearn.linear_model import PassiveAggressiveClassifier as pac\n",
      "from sklearn.linear_model import SGDClassifier as sgd\n",
      "from sklearn.linear_model import Perceptron as pcp\n",
      "from sklearn.svm import SVC\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import datetime as dt\n",
      "from sklearn.metrics import log_loss\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.ensemble import RandomForestClassifier as rfc \n",
      "\n",
      "from sklearn.feature_extraction import DictVectorizer\n",
      "\n",
      "colnames=['C1','banner_pos','site_id','site_domain','site_category','app_id','app_domain','app_category','device_id','device_ip','device_model','device_type','device_conn_type','C14','C15','C16','C17','C18','C19','C20','C21','weekday','hr']\n",
      "vec = DictVectorizer(sparse=True)\n",
      "#clf = bnb()\n",
      "#clf = pac(random_state=0)\n",
      "#clf = sgd(random_state=0)\n",
      "#clf = sgd(random_state=0,loss='log')\n",
      "#clf = pcp(random_state=0)\n",
      "#clf = SVC(C=1000,random_state=0,probability=True,verbose=True,cache_size=1024)\n",
      "clf = rfc(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=1500, min_samples_leaf=10, max_features='auto', max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=-1, random_state=0, verbose=1)\n",
      "#clfb=sgd(random_state=0,loss='log')\n",
      "\n",
      "#Batched reading and learning\n",
      "batch=0\n",
      "nlines=0\n",
      "nlim=200000\n",
      "blim=5\n",
      "btrain=1\n",
      "X=np.zeros((nlim,26),dtype='a20')\n",
      "\n",
      "with open(\"train_woheader.csv\",\"r\") as f:\n",
      "    for line in f:\n",
      "        \n",
      "        X[nlines,:24]=[str(xx) for xx in line.strip().split(',')]\n",
      "        #print X[nlines,:]\n",
      "        X[nlines,24]=str(dt.datetime.strptime(X[nlines,2],'%y%m%d%H').weekday())\n",
      "        X[nlines,25]=X[nlines,2][-2:]\n",
      "        nlines=nlines+1;\n",
      "        if (nlines==nlim):\n",
      "            print 'Processing batch '+str(batch+1)\n",
      "            batch=batch+1\n",
      "\n",
      "            Xd=pd.DataFrame(X[:,3:],columns=colnames)\n",
      "            Y=X[:,1].astype('int')\n",
      "            #All the jazz goes here\n",
      "            if (batch==1):\n",
      "                print 'Running Dict Vectorizer fit transform'\n",
      "                X_sparse=vec.fit_transform(Xd.T.to_dict().values())\n",
      "                print 'training base classifier'\n",
      "                clfb.partial_fit(X_sparse,Y,classes=[0,1])\n",
      "                print X_sparse.shape\n",
      "                print 'training main classifier'\n",
      "                X_sparse_red=clfb.transform(X_sparse,threshold=\"median\").todense()\n",
      "                print X_sparse_red.shape\n",
      "                clf.fit(X_sparse_red,Y)\n",
      "            else:\n",
      "                print 'Running Dict Vectorizer transform alone'\n",
      "                X_sparse=vec.transform(Xd.T.to_dict().values())\n",
      "                X_sparse_red=clfb.transform(X_sparse,threshold=\"median\").todense()\n",
      "                \n",
      "            ypred=clf.predict_proba(X_sparse_red)[:,1]\n",
      "            #lpred=clf.predict(X_sparse)\n",
      "            \n",
      "            #print clf.score(X_sparse,Y), accuracy_score(Y,lpred), log_loss(Y,ypred)\n",
      "            #print clf.score(X_sparse_red,Y), log_loss(Y,ypred)\n",
      "            bconva=float(np.sum(Y))/float(nlim)\n",
      "            print log_loss(Y,ypred),-(bconva*np.log(bconva)+(1-bconva)*np.log(1-bconva))\n",
      "            #print log_loss(Y,ypred), np.mean(Y)\n",
      "            \n",
      "            nlines=0\n",
      "            X=np.zeros((nlim,26),dtype='a20')\n",
      "            del X_sparse, X_sparse_red\n",
      "            \n",
      "            if (batch>=blim):\n",
      "                print \"Done.. aren't we?\"\n",
      "                f.close()\n",
      "                del X\n",
      "                break\n",
      "\n",
      "print 'Yes, we are..'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processing batch 1\n",
        "Running Dict Vectorizer fit transform"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "MemoryError",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-2-c92a475bd841>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[1;32mprint\u001b[0m \u001b[1;34m'Running Dict Vectorizer fit transform'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mX_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m                 \u001b[1;31m#print 'training base classifier'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[1;31m#clfb.partial_fit(X_sparse,Y,classes=[0,1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/tweetytrails/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/dict_vectorizer.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tosequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/tweetytrails/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/dict_vectorizer.pyc\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tosequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m             \u001b[0mXa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mMemoryError\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print clf.score(X_sparse_red,Y), log_loss(Y,ypred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}